{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import yaml\n",
    "import json\n",
    "import datetime\n",
    "from psycopg2.extras import Json\n",
    "from psycopg2.extensions import register_adapter\n",
    "\n",
    "register_adapter(dict, Json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the db_conn YAML file\n",
    "with open('db_conn.yaml', 'r') as file:\n",
    "    yaml_data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS054-E-37430.JPG 2018-02-08 11:51:50\n",
      "ISS054-E-37431.JPG 2018-02-08 11:51:51\n",
      "ISS054-E-37427.JPG 2018-02-08 11:51:47\n",
      "ISS054-E-37429.JPG 2018-02-08 11:51:49\n",
      "ISS054-E-37423.JPG 2018-02-08 11:51:43\n",
      "ISS054-E-37424.JPG 2018-02-08 11:51:44\n",
      "ISS054-E-37425.JPG 2018-02-08 11:51:45\n",
      "ISS054-E-37428.JPG 2018-02-08 11:51:48\n",
      "ISS054-E-3743.JPG 2017-12-24 09:38:03\n",
      "ISS054-E-37432.JPG 2018-02-08 11:51:52\n"
     ]
    }
   ],
   "source": [
    "# Connect to the PostgreSQL database\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host=yaml_data['host'],\n",
    "        port=yaml_data['port'],\n",
    "        database=yaml_data['database'],\n",
    "        user=yaml_data['user'],\n",
    "        password=yaml_data['password']\n",
    "    )\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Define the query to select the first 10 rows\n",
    "    query = \"SELECT * FROM photos.image LIMIT 10;\"\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch the results\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Print the results\n",
    "    for row in rows:\n",
    "        nasa_filename = row[0]\n",
    "        date_time_captured = row[3]\n",
    "        print(nasa_filename, date_time_captured)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Write a query to get all the rows from the photos.image table.\n",
    "# if the results from all of the rows is too big to fit in memory, \n",
    "# you start with a subset of the rows.\n",
    "\n",
    "# 2. Examine the date_time_captured column to look for time lapses movies.\n",
    "# The length of time between images captureed is not specified but should be \n",
    "# constant for a specific time lapse movie, however different time lapse movies \n",
    "# may have different time intervals between images. You can look at other columns\n",
    "# to help identify the time lapse movies, if you think it could help.\n",
    "\n",
    "# 3. Create a list of lists where each sub list contains the nasa_filename of the \n",
    "# images for a specific time lapse movie. \n",
    "\n",
    "# 4. Loop though the list of lists and download the images from the OSN to your \n",
    "# local computer in a new directory based on the nasa_filenames, \n",
    "# ISSMISSION-E-FIRSTFRAME-LASTFRAME, like: /ISS010-E-1000-2000/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# Function to print relevant information on image data\n",
    "# @params rows the output returned by psycopg2's cursor.fetch*() functions\n",
    "# @returns Boolean signifying if the operation was successful\n",
    "def printRows(rows: tuple) -> bool:\n",
    "    # Print the results\n",
    "    try:\n",
    "        for row in rows:\n",
    "            nasa_filename = row[0]\n",
    "            date_time_captured = row[3]\n",
    "            latitude = row[5]\n",
    "            longitude = row[6]\n",
    "            print(nasa_filename, date_time_captured, latitude, longitude)\n",
    "    except Exception as e:\n",
    "        print(f\"an error occured: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        return True\n",
    "\n",
    "# Function to find clusters\n",
    "# Do in increments of 100 entries\n",
    "# @param entries: Assume already given a list of 100 entries of date_time_captured \n",
    "# @return a tuple that contains the starting (inclusive) and ending (exclusive) index of a possible cluster\n",
    "def detect_cluster(entries: list) -> tuple:\n",
    "    start = 100  # Used to track where the cluster started\n",
    "    end = 0  # Used to track where the cluster ended if early\n",
    "    marginOfError = datetime.timedelta(seconds=2)\n",
    "\n",
    "    for i in range(len(entries) - 2):\n",
    "        # Must check at least 3 entries to determine if there is a pattern in increments; use window method\n",
    "        window = [entries[i], entries[i+1], entries[i+2]]\n",
    "        interval1 = window[1] - window[0]\n",
    "        interval2 = window[2] - window[1]\n",
    "        # If the difference in intervals is beyond our margin of error, then this is not a possible timelapse\n",
    "        if (interval1 > interval2+marginOfError or interval1 < interval2-marginOfError):\n",
    "            # End the current cluster if it exists\n",
    "            if start < 100:\n",
    "                end = i+2  # Exclusive\n",
    "                return (start, end)\n",
    "            continue\n",
    "        # Possible timelapse, so take note of beginning index and end index\n",
    "        if i < start: start = i\n",
    "    # Got through entire list, set end to last index\n",
    "    end = 100\n",
    "    return (start, end)\n",
    "\n",
    "# Extract date_time_captured values from query results\n",
    "# @params query_results a list of tuples that represent the rows returned from cursor.fetch*()\n",
    "# @returns a list of datetime objects\n",
    "def get_date_time_captured(query_results: list) -> list:\n",
    "    datetime_list = []\n",
    "    for row in query_results:\n",
    "        datetime_list.append(row[3])\n",
    "    return datetime_list\n",
    "\n",
    "# Transform JSON values in each row into a a compatible string\n",
    "# @params rows a list of tuples that is the output from cursor.fetch*()\n",
    "# @returns a list of newly transformed tuples where the JSONs have been converted into a compatible type from Python to SQL\n",
    "def transform_jsons(rows: list) -> list:\n",
    "    for row in rows:\n",
    "        stringified_json = json.dumps(row[15])\n",
    "        list_row = list(row)\n",
    "        list_row[15] = stringified_json\n",
    "        row = tuple(list_row)\n",
    "    return rows\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host=yaml_data['host'],\n",
    "        port=yaml_data['port'],\n",
    "        database=yaml_data['database'],\n",
    "        user=yaml_data['user'],\n",
    "        password=yaml_data['password']\n",
    "    )\n",
    "    movie_list = []  # Final list of time-lapse movies that will be found\n",
    "    \n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    limit = 200  # Set limit to how many records we want to add to the temp table at a time\n",
    "    offset = 0  # Tracks where we are in the original table\n",
    "    # Define the query to select: Create a virtual table that is sorted by date_time_captured\n",
    "    query_create_view = f\"CREATE TEMPORARY TABLE t_temp AS\\\n",
    "                            SELECT * FROM photos.image\\\n",
    "                            ORDER BY date_time_captured, nasa_filename\\\n",
    "                            LIMIT {limit}\"\n",
    "    # Define query to create a temporary table that will hold a cluster of images\n",
    "    query_create_cluster = \"CREATE TEMP TABLE cluster AS SELECT * FROM photos.image LIMIT 0\"\n",
    "\n",
    "    # Execute creation queries\n",
    "    cursor.execute(query_create_view)\n",
    "    cursor.execute(query_create_cluster)\n",
    "\n",
    "    # Define query to get all records from temp table\n",
    "    query_get_temp_records = \"SELECT * FROM t_temp\"\n",
    "    cursor.execute(query_get_temp_records)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    # We loop finding clusters until our temp table is empty\n",
    "    query_get_size_of_temp_table = \"SELECT count(*) AS exact_count FROM t_temp\"\n",
    "    cursor.execute(query_get_size_of_temp_table)\n",
    "    count = cursor.fetchone()[0]\n",
    "    while (count > 0):\n",
    "        # Get the bounds of our cluster\n",
    "        bounds = detect_cluster(get_date_time_captured(results))\n",
    "        num_rows_to_extract = bounds[1] - bounds[0]\n",
    "    \n",
    "        # Get these rows for the cluster\n",
    "        query_get_cluster_rows = f'SELECT * FROM t_temp ORDER BY date_time_captured, nasa_filename LIMIT {num_rows_to_extract} OFFSET {bounds[0]}'\n",
    "        cursor.execute(query_get_cluster_rows)\n",
    "        rows = cursor.fetchall()\n",
    "    \n",
    "        # Ensure JSONs are transformed into compatible type\n",
    "        transformed_rows = transform_jsons(rows)\n",
    "        \n",
    "        # Slow; TODO: Find way to optimize\n",
    "        # Insert our selected rows into the cluster table\n",
    "        for row in transformed_rows:\n",
    "            # Note: MUST use this format for cursor.execute; just using f'{row}' style will NOT work.\n",
    "            cursor.execute(f'INSERT INTO cluster VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', row)\n",
    "    \n",
    "        # Remove the cluster rows from our temp table\n",
    "        query_remove_rows = f'DELETE FROM t_temp\\\n",
    "                                WHERE date_time_captured IN (\\\n",
    "                                SELECT date_time_captured FROM t_temp\\\n",
    "                                ORDER BY date_time_captured, nasa_filename\\\n",
    "                                LIMIT {bounds[1]})'\n",
    "        cursor.execute(query_remove_rows)\n",
    "    \n",
    "        # Ensure offset is updated \n",
    "        offset = offset + bounds[1]\n",
    "    \n",
    "        # Use offset and limit to fill in our temp table again\n",
    "        query_fill_temp = f\"INSERT INTO t_temp\\\n",
    "                            SELECT * FROM photos.image\\\n",
    "                            WHERE nasa_filename LIKE 'ISS070-E-81___.JPG'\\\n",
    "                            ORDER BY date_time_captured, nasa_filename\\\n",
    "                            LIMIT {limit} OFFSET {offset}\"\n",
    "    \n",
    "        # Extract filenames of our cluster images and put them into a list\n",
    "        cluster = []\n",
    "        query_cluster_filenames = f'SELECT nasa_filename FROM cluster'\n",
    "        cursor.execute(query_cluster_filenames)\n",
    "        query_cluster_result = cursor.fetchall()\n",
    "    \n",
    "        for row in query_cluster_result:\n",
    "            cluster.append(row[0])\n",
    "\n",
    "        # Add the newly found cluster of photos to the movie list\n",
    "        movie_list.append(cluster)\n",
    "\n",
    "        # Clear cluster table\n",
    "        query_clear_cluster = \"TRUNCATE ONLY cluster\"\n",
    "        cursor.execute(query_clear_cluster)\n",
    "\n",
    "        # Get the size of our temp table\n",
    "        cursor.execute(query_get_size_of_temp_table)\n",
    "        count = cursor.fetchone()[0]\n",
    "\n",
    "    print(len(movie_list))\n",
    "   \n",
    "    # ------------ Commands used to try to find out schema ------------ #\n",
    "    #cursor.execute(\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 't_temp'\")\n",
    "    #rows = cursor.fetchall()\n",
    "    #print()\n",
    "    #print(f'printing column names and data types for t_temp: {rows}')\n",
    "\n",
    "    #cursor.execute(\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'cluster'\")\n",
    "    #rows = cursor.fetchall()\n",
    "    #print()\n",
    "    #print(f'printing column names and data types for cluster: {rows}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {type(e)}: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
